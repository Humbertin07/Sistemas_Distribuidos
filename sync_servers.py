#!/usr/bin/env python3
"""
Script para for√ßar sincroniza√ß√£o completa entre os servidores.
Usa os dados do servidor com mais informa√ß√µes como fonte verdadeira.
"""

import json
import os
from collections import defaultdict

def load_json(path):
    """Carrega arquivo JSON"""
    try:
        with open(path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return {} if 'channels.json' in path or 'users.json' in path else []

def save_json(path, data):
    """Salva arquivo JSON"""
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, 'w') as f:
        json.dump(data, f, indent=2)

def merge_data():
    """Mescla dados de todos os servidores"""
    
    servers = ['server1', 'server2', 'server3']
    base_path = '/workspaces/Sistemas_Distribuidos/data'
    
    # Coletar todos os dados
    all_users = {}
    all_channels = {}
    all_messages = []
    all_publications = []
    seen_msg_ids = set()
    seen_pub_ids = set()
    
    print("üìä Coletando dados de todos os servidores...")
    
    for server in servers:
        server_path = f"{base_path}/{server}"
        
        # Usu√°rios
        users = load_json(f"{server_path}/users.json")
        for username, data in users.items():
            if username not in all_users:
                all_users[username] = data
        
        # Canais
        channels = load_json(f"{server_path}/channels.json")
        for channel_name, data in channels.items():
            if channel_name not in all_channels:
                all_channels[channel_name] = data
        
        # Mensagens
        messages = load_json(f"{server_path}/messages.json")
        for msg in messages:
            msg_id = msg.get('id')
            if msg_id and msg_id not in seen_msg_ids:
                all_messages.append(msg)
                seen_msg_ids.add(msg_id)
        
        # Publica√ß√µes
        publications = load_json(f"{server_path}/publications.json")
        for pub in publications:
            pub_id = pub.get('id')
            if pub_id and pub_id not in seen_pub_ids:
                all_publications.append(pub)
                seen_pub_ids.add(pub_id)
    
    # Ordenar por timestamp/lamport_clock
    all_messages.sort(key=lambda x: (x.get('timestamp', ''), x.get('lamport_clock', 0)))
    all_publications.sort(key=lambda x: (x.get('timestamp', ''), x.get('lamport_clock', 0)))
    
    print(f"\n‚úÖ Dados consolidados:")
    print(f"   - {len(all_users)} usu√°rios √∫nicos")
    print(f"   - {len(all_channels)} canais √∫nicos")
    print(f"   - {len(all_messages)} mensagens √∫nicas")
    print(f"   - {len(all_publications)} publica√ß√µes √∫nicas")
    
    # Salvar dados unificados em todos os servidores
    print("\nüîÑ Sincronizando dados para todos os servidores...")
    
    for server in servers:
        server_path = f"{base_path}/{server}"
        
        save_json(f"{server_path}/users.json", all_users)
        save_json(f"{server_path}/channels.json", all_channels)
        save_json(f"{server_path}/messages.json", all_messages)
        save_json(f"{server_path}/publications.json", all_publications)
        
        print(f"   ‚úì {server} atualizado")
    
    print("\n‚ú® Sincroniza√ß√£o completa!")
    
    # Estat√≠sticas por servidor (antes da sincroniza√ß√£o)
    print("\nüìà Compara√ß√£o de dados (antes da sincroniza√ß√£o):")
    for server in servers:
        server_path = f"{base_path}/{server}"
        users = load_json(f"{server_path}/users.json")
        channels = load_json(f"{server_path}/channels.json")
        messages = load_json(f"{server_path}/messages.json")
        publications = load_json(f"{server_path}/publications.json")
        
        print(f"\n   {server}:")
        print(f"      - Usu√°rios: {len(users)}")
        print(f"      - Canais: {len(channels)}")
        print(f"      - Mensagens: {len(messages)}")
        print(f"      - Publica√ß√µes: {len(publications)}")

if __name__ == '__main__':
    merge_data()
